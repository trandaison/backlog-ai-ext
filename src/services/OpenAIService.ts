import { availableModels, defaultModelId } from '../configs/aiModels';
import ContextOptimizer from '../shared/contextOptimizer';
import { SettingsService } from '../shared/settingsService';
import { AIService } from '../types';
import { FileAttachment } from '../types/attachment';
import { TicketData } from '../types/backlog';
import { Settings } from '../types/settings';

export class OpenAIService implements AIService {
  private apiKey: string = '';
  private apiUrl: string = 'https://api.openai.com/v1/chat/completions';

  constructor() {
    this.loadApiKey();
  }

  private async loadApiKey() {
    try {
      const settingsService = SettingsService.getInstance();
      const aiModelSettings = await settingsService.getAiModelSettings();
      this.apiKey = aiModelSettings.aiProviderKeys.openAi || '';
    } catch (error) {
      console.error('Failed to load/decrypt API key:', error);
      this.apiKey = '';
    }
  }

  private getOpenAIModel(settings?: Settings): string {
    const preferredModel = settings?.aiModels.preferredModel || defaultModelId;

    // Map preferred model to actual OpenAI API model name
    const modelMap: Record<string, string> = {
      'o3': 'o3',
      'o3-pro': 'o3-pro',
      'o3-mini': 'o3-mini',
      'gpt-4.1': 'gpt-4',
      'gpt-4.1-mini': 'gpt-4-turbo',
      'gpt-4.1-nano': 'gpt-3.5-turbo',
      'gpt-4o': 'gpt-4o',
      'chatgpt-4o': 'gpt-4o',
      'gpt-4o-mini': 'gpt-4o-mini',
      'o4-mini': 'gpt-4o-mini'
    };

    const mappedModel = modelMap[preferredModel] || preferredModel;

    // Ensure we only use valid OpenAI models
    const validOpenAIModels = [
      'gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo', 'gpt-4o', 'gpt-4o-mini',
      'o3', 'o3-pro', 'o3-mini'
    ];

    // Use default model mapping if current model is not OpenAI
    const defaultModel = availableModels.find(m => m.id === defaultModelId);
    const fallbackModel = defaultModel?.provider === 'openai'
      ? (modelMap[defaultModelId] || 'gpt-4o-mini')
      : 'gpt-4o-mini';

    return validOpenAIModels.includes(mappedModel) ? mappedModel : fallbackModel;
  }

  async analyzeTicket(ticketData: TicketData, settings?: Settings): Promise<string> {
    const apiKey = this.apiKey;
    if (!apiKey) {
      await this.loadApiKey(); // Try to reload in case it was updated
      const fallbackApiKey = this.apiKey;
      if (!fallbackApiKey) {
        return 'API key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng v√†o popup ƒë·ªÉ c√†i ƒë·∫∑t.';
      }
    }

    const finalApiKey = this.apiKey;
    const prompt = this.buildTicketAnalysisPrompt(ticketData, settings);

    try {
      const response = await fetch(this.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${finalApiKey}`
        },
        body: JSON.stringify({
          model: this.getOpenAIModel(settings),
          messages: [
            {
              role: 'system',
              content: this.buildSystemPrompt(settings)
            },
            {
              role: 'user',
              content: prompt
            }
          ],
          max_tokens: 1000,
          temperature: 0.7
        })
      });

      const data = await response.json();

      if (data.choices && data.choices[0]) {
        return data.choices[0].message.content;
      } else {
        throw new Error('Invalid API response');
      }
    } catch (error) {
      console.error('Error calling OpenAI API:', error);
      return `L·ªói khi g·ªçi AI API: ${error}`;
    }
  }

  async processUserMessage(message: string, contextData: any, settings?: Settings, attachments?: FileAttachment[]): Promise<{
    response: string;
    responseId?: string;
    tokensUsed?: number;
  }> {
    const apiKey = this.apiKey;
    if (!apiKey) {
      return {
        response: 'API key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng v√†o popup ƒë·ªÉ c√†i ƒë·∫∑t.',
        tokensUsed: 0
      };
    }

    // Build prompt based on whether comment context is present
    let finalPrompt: string;

    if (contextData.commentContext) {
      // Build comment-focused prompt
      finalPrompt = this.buildCommentPrompt(message, contextData, settings);
    } else {
      // Build enhanced message with attachments if any
      finalPrompt = message;
      if (attachments && attachments.length > 0) {
        finalPrompt = this.buildMessageWithAttachments(message, attachments);
      }

      // Check if this is optimized context from ContextOptimizer
      if (contextData.isOptimized) {
        // Use the optimized context as is
      } else {
        // Build regular chat prompt for legacy handling
        finalPrompt = this.buildChatPrompt(message, contextData, settings);
      }
    }

    // Log the final prompt for review
    console.log('üîç [OpenAI] Final prompt being sent to AI:', finalPrompt);

    // Build messages array for OpenAI with multimodal support
    const userContent: any[] = [{
      type: 'text',
      text: finalPrompt
    }];

    // Add image attachments for GPT-4V
    if (attachments && attachments.length > 0) {
      for (const attachment of attachments) {
        if (attachment.base64 && attachment.type.startsWith('image/')) {
          userContent.push({
            type: 'image_url',
            image_url: {
              url: `data:${attachment.type};base64,${attachment.base64}`
            }
          });
        }
      }
    }

    const messages = [
      {
        role: 'system',
        content: this.buildSystemPrompt(settings)
      },
      {
        role: 'user',
        content: userContent.length === 1 ? finalPrompt : userContent
      }
    ];

    try {
      const response = await fetch(this.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify({
          model: this.getOpenAIModel(settings),
          messages,
          max_tokens: 1500, // Increased from 800
          temperature: 0.7
        })
      });

      const data = await response.json();

      if (data.choices && data.choices[0]) {
        const content = data.choices[0].message.content;
        const tokensUsed = data.usage?.total_tokens || ContextOptimizer.estimateTokenCount(content);
        const responseId = data.id;

        return {
          response: content,
          responseId,
          tokensUsed
        };
      } else {
        throw new Error('Invalid API response');
      }
    } catch (error) {
      console.error('Error calling OpenAI API:', error);
      return {
        response: `L·ªói khi g·ªçi AI API: ${error}`,
        tokensUsed: 0
      };
    }
  }

  private buildMessageWithAttachments(message: string, attachments: FileAttachment[]): string {
    let enhancedMessage = message;

    for (const attachment of attachments) {
      enhancedMessage += `\n\n**File: ${attachment.name}** (${attachment.type}, ${this.formatFileSize(attachment.size)})\n`;

      if (attachment.type.startsWith('text/') && attachment.base64) {
        // For text files, decode and include full content
        try {
          const fullContent = atob(attachment.base64);
          enhancedMessage += `N·ªôi dung file:\n\`\`\`\n${fullContent}\n\`\`\`\n`;
        } catch (error) {
          enhancedMessage += `[L·ªói ƒë·ªçc file text: ${error}]\n`;
        }
      } else if (attachment.preview) {
        // Fallback to preview if base64 not available
        enhancedMessage += `Content preview:\n\`\`\`\n${attachment.preview}\n\`\`\`\n`;
      } else if (attachment.base64) {
        // For binary files, mention they are attached
        if (attachment.type.startsWith('image/')) {
          enhancedMessage += `[Image file attached - please analyze the visual content]\n`;
        } else {
          enhancedMessage += `[Binary file attached - content type: ${attachment.type}]\n`;
        }
      }
    }

    return enhancedMessage;
  }

  private formatFileSize(bytes: number): string {
    if (bytes === 0) return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(1)) + ' ' + sizes[i];
  }

  private buildTicketAnalysisPrompt(ticketData: TicketData, settings?: Settings): string {
    const roleContext = this.getRoleContext(settings?.general.userRole || 'developer');
    const languagePrompt = this.getLanguagePrompt(settings?.general.language || 'vi');

    return `${languagePrompt}

${roleContext}

H√£y ph√¢n t√≠ch ticket Backlog sau:

**ID**: ${ticketData.id || 'Unknown'}
**Ti√™u ƒë·ªÅ**: ${ticketData.title || 'No title'}
**M√¥ t·∫£**: ${ticketData.description || 'No description'}
**Tr·∫°ng th√°i**: ${ticketData.status || 'Unknown'}
**ƒê·ªô ∆∞u ti√™n**: ${ticketData.priority || 'Unknown'}
**Ng∆∞·ªùi ƒë∆∞·ª£c g√°n**: ${ticketData.assignee || 'Unassigned'}
**Ng∆∞·ªùi b√°o c√°o**: ${ticketData.reporter || 'Unknown'}
**H·∫°n**: ${ticketData.dueDate || 'No due date'}
**Labels**: ${Array.isArray(ticketData.labels) ? ticketData.labels.join(', ') : 'No labels'}

**Comments**:
${ticketData.comments
  .filter((comment: any) => comment.content && comment.content.trim())
  .sort((a: any, b: any) => {
    // Sort by timestamp field ascending (oldest first, newest last)
    // timestamp contains ISO 8601 format from Backlog API's 'created' field
    const timeA = new Date(a.timestamp || a.created || 0).getTime();
    const timeB = new Date(b.timestamp || b.created || 0).getTime();
    return timeA - timeB;
  })
  .map((comment: any) => {
    const content = comment.content || '';
    return `- ${comment.author} (${comment.timestamp}): ${content}`;
  }).join('\n')}

H√£y ƒë∆∞a ra:
1. T√≥m t·∫Øt n·ªôi dung ticket
2. Ph√¢n t√≠ch m·ª©c ƒë·ªô ph·ª©c t·∫°p
3. ƒê·ªÅ xu·∫•t approach ƒë·ªÉ gi·∫£i quy·∫øt
4. Nh·ªØng ƒëi·ªÉm c·∫ßn ch√∫ √Ω
5. Timeline ∆∞·ªõc t√≠nh (n·∫øu c√≥ th·ªÉ)
`;
  }

  private buildSystemPrompt(settings?: Settings): string {
    const roleContext = this.getRoleContext(settings?.general.userRole || 'developer');
    const languageContext = this.getLanguagePrompt(settings?.general.language || 'vi');

    let systemPrompt = `${languageContext}

${roleContext}

B·∫°n l√† AI assistant chuy√™n h·ªó tr·ª£ ph√¢n t√≠ch v√† th·∫£o lu·∫≠n v·ªÅ ticket Backlog.
B·∫°n c√≥ th·ªÉ:
- Ph√¢n t√≠ch chi ti·∫øt n·ªôi dung ticket
- ƒê·ªÅ xu·∫•t gi·∫£i ph√°p k·ªπ thu·∫≠t
- Gi·∫£i th√≠ch c√°c kh√°i ni·ªám k·ªπ thu·∫≠t
- H·ªó tr·ª£ communication gi·ªØa c√°c team member
- ƒê∆∞a ra estimate v√† timeline
- Translate v√† explain content

H√£y response m·ªôt c√°ch chuy√™n nghi·ªáp, chi ti·∫øt v√† h·ªØu √≠ch.`;

    return systemPrompt;
  }

  private getRoleContext(userRole: string): string {
    const roleContexts = {
      developer: `
B·∫°n ƒëang t∆∞∆°ng t√°c v·ªõi m·ªôt Developer/Engineer. H√£y focus v√†o:
- Technical implementation details
- Code architecture v√† design patterns
- Performance v√† optimization
- Security considerations
- Development best practices`,
      pm: `
B·∫°n ƒëang t∆∞∆°ng t√°c v·ªõi m·ªôt Project Manager. H√£y focus v√†o:
- Project timeline v√† milestones
- Resource planning v√† allocation
- Risk assessment v√† mitigation
- Stakeholder communication
- Delivery estimation`,
      qa: `
B·∫°n ƒëang t∆∞∆°ng t√°c v·ªõi m·ªôt QA/Testing specialist. H√£y focus v√†o:
- Test cases v√† test scenarios
- Quality assurance processes
- Bug reproduction steps
- Testing strategies
- Quality metrics`,
      designer: `
B·∫°n ƒëang t∆∞∆°ng t√°c v·ªõi m·ªôt Designer. H√£y focus v√†o:
- User experience v√† user interface
- Design consistency v√† guidelines
- Accessibility considerations
- Visual design elements
- User journey optimization`,
      devops: `
B·∫°n ƒëang t∆∞∆°ng t√°c v·ªõi m·ªôt DevOps engineer. H√£y focus v√†o:
- Infrastructure v√† deployment
- CI/CD pipeline optimization
- Monitoring v√† alerting
- System reliability
- Performance tuning`,
      other: `
B·∫°n ƒëang t∆∞∆°ng t√°c v·ªõi m·ªôt team member. H√£y cung c·∫•p:
- General overview v√† context
- Clear explanations
- Actionable insights
- Collaborative recommendations`
    };

    return roleContexts[userRole as keyof typeof roleContexts] || roleContexts.other;
  }

  private getLanguagePrompt(language: string): string {
    const languagePrompts = {
      vi: `H√£y respond b·∫±ng ti·∫øng Vi·ªát. Gi·ªØ technical terms b·∫±ng ti·∫øng Anh khi c·∫ßn thi·∫øt.`,
      en: `Please respond in English with clear and professional language.`,
      ja: `Êó•Êú¨Ë™û„ÅßÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÊäÄË°ìÁî®Ë™û„ÅØÈÅ©Âàá„Å´‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ`
    };

    return languagePrompts[language as keyof typeof languagePrompts] || languagePrompts.vi;
  }

  private buildChatPrompt(message: string, context: any, settings?: Settings): string {
    const language = settings?.general.language === 'vi' ? 'ti·∫øng Vi·ªát' : 'English';
    const role = settings?.general.userRole || 'developer';

    let prompt = `B·∫°n l√† m·ªôt AI assistant chuy√™n h·ªó tr·ª£ ${role} trong vi·ªác x·ª≠ l√Ω ticket/issue.
H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau b·∫±ng ${language}:\n\n`;

    if (context.ticketData) {
      prompt += `**B·ªëi c·∫£nh ticket hi·ªán t·∫°i:**
- ID: ${context.ticketData.id}
- Ti√™u ƒë·ªÅ: ${context.ticketData.title}
- Tr·∫°ng th√°i: ${context.ticketData.status}\n\n`;
    }

    if (context.chatHistory && context.chatHistory.length > 0) {
      prompt += `**L·ªãch s·ª≠ chat g·∫ßn ƒë√¢y:**\n`;
      context.chatHistory.slice(-3).forEach((msg: any) => {
        prompt += `${msg.sender}: ${msg.content}\n`;
      });
      prompt += '\n';
    }

    prompt += `**C√¢u h·ªèi:** ${message}`;

    return prompt;
  }

  private buildCommentPrompt(message: string, context: any, settings?: Settings): string {
    const language = settings?.general.language === 'vi' ? 'ti·∫øng Vi·ªát' : 'English';
    const role = settings?.general.userRole || 'developer';

    let prompt = `B·∫°n l√† m·ªôt AI assistant chuy√™n h·ªó tr·ª£ ${role} trong vi·ªác x·ª≠ l√Ω ticket/issue.
H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau b·∫±ng ${language}:\n\n`;

    // Add ticket context
    if (context.ticketData) {
      prompt += `B·ªëi c·∫£nh ticket:
- ID: ${context.ticketData.id}
- Ti√™u ƒë·ªÅ: ${context.ticketData.title}
- Tr·∫°ng th√°i: ${context.ticketData.status}
- M√¥ t·∫£ ticket: ${context.ticketData.description || 'Kh√¥ng c√≥ m√¥ t·∫£'}\n\n`;
    }

    // Add selected comment context
    const commentContext = context.commentContext;
    if (commentContext && commentContext.selectedComment) {
      const selectedComment = commentContext.selectedComment;
      const createdDate = selectedComment.created ? new Date(selectedComment.created).toLocaleString('vi-VN') : 'Kh√¥ng r√µ';

      prompt += `Comment c·∫ßn ph√¢n t√≠ch (ng∆∞·ªùi d√πng t·∫≠p trung v√†o comment n√†y):
- Ng∆∞·ªùi g·ª≠i: ${selectedComment.createdUser?.name || 'Kh√¥ng r√µ'}
- Th·ªùi gian: ${createdDate}
- N·ªôi dung: ${selectedComment.content || 'Kh√¥ng c√≥ n·ªôi dung'}\n\n`;
    }

    // Add previous comments for context
    if (commentContext && commentContext.previousComments && commentContext.previousComments.length > 0) {
      prompt += `2 comments g·∫ßn ƒë√≥ nh·∫•t cho vi·ªác tham kh·∫£o c√°c th√¥ng tin li√™n quan:\n`;

      commentContext.previousComments.slice(0, 2).forEach((comment: any, index: number) => {
        const createdDate = comment.created ? new Date(comment.created).toLocaleString('vi-VN') : 'Kh√¥ng r√µ';
        prompt += `${index + 1}. ${comment.createdUser?.name || 'Kh√¥ng r√µ'} l√∫c ${createdDate} v·ªõi n·ªôi dung: ${comment.content || 'Kh√¥ng c√≥ n·ªôi dung'}\n`;
      });
      prompt += '\n';
    }

    prompt += `---\nC√¢u h·ªèi: ${message}`;

    return prompt;
  }
}

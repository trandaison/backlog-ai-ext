import { availableModels, defaultModelId } from '../configs/aiModels';
import ContextOptimizer from '../shared/contextOptimizer';
import { SettingsService } from '../shared/settingsService';
import { AIService } from '../types';
import { FileAttachment } from '../types/attachment';
import { TicketData } from '../types/backlog';
import { Settings } from '../types/settings';

export class GeminiService implements AIService {
  private apiKey: string = '';
  private baseApiUrl: string =
    'https://generativelanguage.googleapis.com/v1beta/models';

  constructor() {
    this.loadApiKey();
  }

  private async loadApiKey() {
    try {
      const settingsService = SettingsService.getInstance();
      const aiModelSettings = await settingsService.getAiModelSettings();
      this.apiKey = aiModelSettings.aiProviderKeys.gemini || '';
    } catch (error) {
      console.error('‚ùå [Gemini] Error loading API key:', error);
      this.apiKey = '';
    }
  }

  // Map preferred model to actual Gemini API model name
  private getGeminiModelName(preferredModel?: string): string {
    if (!preferredModel) {
      // Use default model from config and map to actual Gemini model
      const defaultModel = availableModels.find((m) => m.id === defaultModelId);
      if (defaultModel?.provider === 'gemini') {
        return this.mapToGeminiAPI(defaultModelId);
      }
      return 'gemini-2.0-flash-exp'; // Updated fallback to Gemini 2.0
    }

    return this.mapToGeminiAPI(preferredModel);
  }

  private mapToGeminiAPI(modelId: string): string {
    // Map our model IDs to actual Gemini API model names
    // All 2.5 variants use Gemini 2.0 Flash Experimental for consistency
    const modelMap: Record<string, string> = {
      'gemini-2.5-pro': 'gemini-2.0-flash-exp',
      'gemini-2.5-flash': 'gemini-2.0-flash-exp',
      'gemini-2.5-flash-lite': 'gemini-2.0-flash-exp', // ‚úÖ Now uses Gemini 2.0 as expected
      // OpenAI models that might accidentally come through
      'gpt-4o': 'gemini-2.0-flash-exp', // fallback
      'gpt-4o-mini': 'gemini-2.0-flash-exp', // fallback
      'o1-preview': 'gemini-2.0-flash-thinking-exp', // reasoning model
      'o1-mini': 'gemini-2.0-flash-thinking-exp', // reasoning model
      'o3-mini': 'gemini-2.0-flash-thinking-exp', // reasoning model
    };

    return modelMap[modelId] || 'gemini-2.0-flash-exp';
  }
  private getApiUrl(model: string = 'gemini-2.0-flash-exp'): string {
    return `${this.baseApiUrl}/${model}:generateContent`;
  }

  async analyzeTicket(
    ticketData: TicketData,
    settings?: Settings
  ): Promise<string> {
    const prompt = this.buildAnalysisPrompt(ticketData, settings);
    const result = await this.callGeminiAPI(prompt, settings);
    return result.response;
  }

  async processUserMessage(
    message: string,
    contextData: any,
    settings?: Settings,
    attachments?: FileAttachment[]
  ): Promise<{
    response: string;
    responseId?: string;
    tokensUsed?: number;
  }> {
    console.log(
      'üîé ~ GeminiService ~ processUserMessage ~ contextData:',
      contextData
    );
    // Build prompt based on whether comment context is present
    let finalPrompt: string;

    if (contextData.commentContext) {
      // Build comment-focused prompt
      finalPrompt = this.buildCommentPrompt(message, contextData, settings);
    } else {
      // Build enhanced message with attachments if any
      finalPrompt = message;
      if (attachments && attachments.length > 0) {
        finalPrompt = this.buildMessageWithAttachments(message, attachments);
      }

      // Check if this is optimized context from ContextOptimizer
      if (contextData.isOptimized) {
        // Use the optimized context as is
      } else {
        // Build regular chat prompt for legacy handling
        finalPrompt = this.buildChatPrompt(message, contextData, settings);
      }
    }

    // Log the final prompt for review
    console.log('üîç [Gemini] Final prompt being sent to AI:', finalPrompt);

    const result = await this.callGeminiAPI(finalPrompt, settings, attachments);
    return {
      response: result.response,
      responseId: result.responseId,
      tokensUsed:
        result.tokensUsed ||
        ContextOptimizer.estimateTokenCount(result.response),
    };
  }

  private buildMessageWithAttachments(
    message: string,
    attachments: FileAttachment[]
  ): string {
    let enhancedMessage = message;

    for (const attachment of attachments) {
      enhancedMessage += `\n\n**File: ${attachment.name}** (${
        attachment.type
      }, ${this.formatFileSize(attachment.size)})\n`;

      // For files that will be sent as inline_data, just mention them
      if (
        attachment.type.startsWith('image/') ||
        attachment.type.startsWith('text/') ||
        attachment.type.includes('csv') ||
        attachment.type.includes('json') ||
        attachment.type.includes('plain')
      ) {
        enhancedMessage += `[File content will be processed by AI - please analyze this file]\n`;
      } else if (attachment.preview) {
        // For other files with preview, include preview
        enhancedMessage += `Content preview:\n\`\`\`\n${attachment.preview}\n\`\`\`\n`;
      } else {
        enhancedMessage += `[Binary file attached - content type: ${attachment.type}]\n`;
      }
    }

    return enhancedMessage;
  }

  private formatFileSize(bytes: number): string {
    if (bytes === 0) return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(1)) + ' ' + sizes[i];
  }

  private buildAnalysisPrompt(
    ticketData: TicketData,
    settings?: Settings
  ): string {
    const language =
      settings?.general.language === 'vi' ? 'ti·∫øng Vi·ªát' : 'English';
    const role = settings?.general.userRole || 'developer';

    return `B·∫°n l√† m·ªôt AI assistant chuy√™n ph√¢n t√≠ch ticket/issue cho ${role}.
H√£y ph√¢n t√≠ch ticket sau v√† ƒë∆∞a ra nh·∫≠n x√©t h·ªØu √≠ch b·∫±ng ${language}:

**Th√¥ng tin ticket:**
- ID: ${ticketData.id}
- Ti√™u ƒë·ªÅ: ${ticketData.title}
- M√¥ t·∫£: ${ticketData.description}
- Tr·∫°ng th√°i: ${ticketData.status}
- ƒê·ªô ∆∞u ti√™n: ${ticketData.priority}
- Ng∆∞·ªùi ƒë∆∞·ª£c giao: ${ticketData.assignee}
- Ng∆∞·ªùi b√°o c√°o: ${ticketData.reporter}
- H·∫°n ch√≥t: ${ticketData.dueDate}
- Nh√£n: ${ticketData.labels?.join(', ')}

H√£y cung c·∫•p:
1. T√≥m t·∫Øt ng·∫Øn g·ªçn
2. M·ª©c ƒë·ªô ph·ª©c t·∫°p v√† ∆∞·ªõc t√≠nh th·ªùi gian
3. C√°c b∆∞·ªõc x·ª≠ l√Ω ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t
4. R·ªßi ro v√† l∆∞u √Ω c·∫ßn ch√∫ √Ω`;
  }

  private buildChatPrompt(
    message: string,
    context: any,
    settings?: Settings
  ): string {
    const language =
      settings?.general.language === 'vi' ? 'ti·∫øng Vi·ªát' : 'English';
    const role = settings?.general.userRole || 'developer';

    let prompt = `B·∫°n l√† m·ªôt AI assistant chuy√™n h·ªó tr·ª£ ${role} trong vi·ªác x·ª≠ l√Ω ticket/issue.
H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau b·∫±ng ${language}:\n\n`;

    if (context.ticketData) {
      prompt += `**B·ªëi c·∫£nh ticket hi·ªán t·∫°i:**
- ID: ${context.ticketData.id}
- Ti√™u ƒë·ªÅ: ${context.ticketData.title}
- Tr·∫°ng th√°i: ${context.ticketData.status}\n\n`;
    }

    if (context.chatHistory && context.chatHistory.length > 0) {
      prompt += `**L·ªãch s·ª≠ chat g·∫ßn ƒë√¢y:**\n`;
      context.chatHistory.slice(-3).forEach((msg: any) => {
        prompt += `${msg.sender}: ${msg.content}\n`;
      });
      prompt += '\n';
    }

    prompt += `**C√¢u h·ªèi:** ${message}`;

    return prompt;
  }

  private buildCommentPrompt(
    message: string,
    context: any,
    settings?: Settings
  ): string {
    const language =
      settings?.general.language === 'vi' ? 'ti·∫øng Vi·ªát' : 'English';
    const role = settings?.general.userRole || 'developer';

    let prompt = `B·∫°n l√† m·ªôt AI assistant chuy√™n h·ªó tr·ª£ ${role} trong vi·ªác x·ª≠ l√Ω ticket/issue.
H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau b·∫±ng ${language}:\n\n`;

    // Add ticket context
    if (context.ticketData) {
      prompt += `B·ªëi c·∫£nh ticket:
- ID: ${context.ticketData.id}
- Ti√™u ƒë·ªÅ: ${context.ticketData.title}
- Tr·∫°ng th√°i: ${context.ticketData.status}
- M√¥ t·∫£ ticket: ${context.ticketData.description || 'Kh√¥ng c√≥ m√¥ t·∫£'}\n\n`;
    }

    // Add selected comment context
    const commentContext = context.commentContext;
    if (commentContext && commentContext.selectedComment) {
      const selectedComment = commentContext.selectedComment;
      const createdDate = selectedComment.created
        ? new Date(selectedComment.created).toLocaleString('vi-VN')
        : 'Kh√¥ng r√µ';

      prompt += `Comment c·∫ßn ph√¢n t√≠ch (ng∆∞·ªùi d√πng t·∫≠p trung v√†o comment n√†y):
- Ng∆∞·ªùi g·ª≠i: ${selectedComment.createdUser?.name || 'Kh√¥ng r√µ'}
- Th·ªùi gian: ${createdDate}
- N·ªôi dung: ${selectedComment.content || 'Kh√¥ng c√≥ n·ªôi dung'}\n\n`;
    }

    // Add previous comments for context
    if (
      commentContext &&
      commentContext.previousComments &&
      commentContext.previousComments.length > 0
    ) {
      prompt += `2 comments g·∫ßn ƒë√≥ nh·∫•t cho vi·ªác tham kh·∫£o c√°c th√¥ng tin li√™n quan:\n`;

      commentContext.previousComments
        .slice(0, 2)
        .forEach((comment: any, index: number) => {
          const createdDate = comment.created
            ? new Date(comment.created).toLocaleString('vi-VN')
            : 'Kh√¥ng r√µ';
          prompt += `${index + 1}. ${
            comment.createdUser?.name || 'Kh√¥ng r√µ'
          } l√∫c ${createdDate} v·ªõi n·ªôi dung: ${
            comment.content || 'Kh√¥ng c√≥ n·ªôi dung'
          }\n`;
        });
      prompt += '\n';
    }

    prompt += `---\nC√¢u h·ªèi: ${message}`;

    return prompt;
  }

  private async callGeminiAPI(
    prompt: string,
    settings?: Settings,
    attachments?: FileAttachment[]
  ): Promise<{
    response: string;
    responseId?: string;
    tokensUsed?: number;
  }> {
    try {
      const apiKey = this.apiKey;
      if (!apiKey) {
        return {
          response:
            'Gemini API key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng v√†o popup ƒë·ªÉ c√†i ƒë·∫∑t.',
          tokensUsed: 0,
        };
      }

      // Get the actual Gemini model name from preferred model
      const geminiModel = this.getGeminiModelName(
        settings?.aiModels.preferredModel || undefined
      );
      const apiUrl = this.getApiUrl(geminiModel);

      // Build parts array for multimodal content
      const parts: any[] = [
        {
          text: prompt,
        },
      ];

      // Add attachments if any
      if (attachments && attachments.length > 0) {
        console.log('üìé [Gemini] Processing attachments:', attachments.length);
        for (const attachment of attachments) {
          console.log(
            'üìé [Gemini] Attachment:',
            attachment.name,
            attachment.type,
            'has base64:',
            !!attachment.base64
          );
          if (attachment.base64) {
            // For images, add as inline_data for vision processing
            if (attachment.type.startsWith('image/')) {
              console.log(
                'üñºÔ∏è [Gemini] Adding image attachment:',
                attachment.name
              );
              parts.push({
                inline_data: {
                  mime_type: attachment.type,
                  data: attachment.base64,
                },
              });
            }
            // For text files (CSV, TXT, JSON, etc), also add as inline_data for better processing
            else if (
              attachment.type.startsWith('text/') ||
              attachment.type.includes('csv') ||
              attachment.type.includes('json') ||
              attachment.type.includes('plain')
            ) {
              console.log(
                'üìÑ [Gemini] Adding text file as inline_data:',
                attachment.name
              );
              parts.push({
                inline_data: {
                  mime_type: attachment.type,
                  data: attachment.base64,
                },
              });
            }
            // For other binary files, mention in text (already included in prompt)
          }
        }
      }

      console.log(
        'üöÄ [Gemini] Final parts array:',
        parts.length,
        parts.map((p) =>
          p.inline_data ? `inline_data: ${p.inline_data.mime_type}` : 'text'
        )
      );

      const response = await fetch(`${apiUrl}?key=${apiKey}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [
            {
              parts: parts,
            },
          ],
          generationConfig: {
            temperature: 0.3,
            topK: 40,
            topP: 0.95,
            maxOutputTokens: 4096, // Increased from 1024 to handle longer responses
          },
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå [Gemini] API Error Response:', errorText);
        throw new Error(`Gemini API Error ${response.status}: ${errorText}`);
      }

      const data = await response.json();

      if (data.error) {
        throw new Error(
          `Gemini API Error: ${
            data.error.message || JSON.stringify(data.error)
          }`
        );
      }

      if (
        data.candidates &&
        data.candidates[0] &&
        data.candidates[0].content &&
        data.candidates[0].content.parts &&
        data.candidates[0].content.parts[0]
      ) {
        const content = data.candidates[0].content.parts[0].text;
        const responseId =
          data.candidates[0].citationMetadata?.citationSources?.[0]?.endIndex?.toString() ||
          undefined;
        const tokensUsed =
          data.usageMetadata?.totalTokenCount ||
          ContextOptimizer.estimateTokenCount(content);

        return {
          response: content,
          responseId,
          tokensUsed,
        };
      } else {
        console.error('‚ùå [Gemini] Invalid API response structure:', data);
        throw new Error(
          'Invalid Gemini API response - no content in candidates'
        );
      }
    } catch (error) {
      console.error('‚ùå [Gemini] Error calling API:', error);
      throw error;
    }
  }
}
